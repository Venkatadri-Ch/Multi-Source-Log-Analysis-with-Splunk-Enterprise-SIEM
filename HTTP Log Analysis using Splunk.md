# Analyzing HTTP Logs Using Splunk SIEM

### Introduction

HTTP (Hypertext Transfer Protocol) logs provide important insights into web server activity, capturing details such as requests, responses, user agents, and other relevant information. By analyzing these logs using Splunk SIEM, security professionals can effectively monitor web traffic, detect unusual patterns, and identify potential security threats.

### Project Overview

In this project, we will upload sample HTTP logs into Splunk SIEM and analyze them to gain insights into web server activity across the network. The analysis will help us understand traffic patterns, identify anomalies, and explore potential security concerns.

### Prerequisites

Before starting the project, ensure the following:

- Splunk is installed and configured.
- [HTTP log dataset](https://www.secrepo.com/maccdc2012/http.log.gz).

Note: The steps to upload the sample HTTP log to Splunk are the same as those used for the previous DNS log analysis.

I have given the source type name as httplogs and the description as This is HTTP log data.

<img width="931" height="413" alt="httplogs source type 1" src="https://github.com/user-attachments/assets/33f6abe7-0ce7-40f8-8879-15c5c0b2211c" />

# Analyzing HTTP Logs with Splunk

### 1. Search for HTTP Events

Open the Splunk interface and go to the Search bar.
To view the HTTP events, run the following search query:
```
index=_* or index=* sourcetype=httplogs
```
This query retrieves all the HTTP events from the specified index and source type.

<img width="943" height="421" alt="full http events 3" src="https://github.com/user-attachments/assets/fcb0ca31-c09f-479b-85d5-dc81932fbb6d" />

### 2. Extracted Fields

Using the same field extraction steps as in the previous DNS log analysis, I extracted the src_port, dst_port, and status (I mean HTTP status codes) fields.

<img width="946" height="407" alt="extracted(dp,sp,status) 4" src="https://github.com/user-attachments/assets/6d3f4860-a582-453a-b4f0-ada0c2c8f319" />

Here, we can see the HTTP status codes, HTTP status codes are standardized three-digit codes returned by web servers in response to client requests.
They indicate whether a request has been successfully completed, redirected, or resulted in an error.

<img width="951" height="422" alt="http status codes 5" src="https://github.com/user-attachments/assets/69c32611-9ad5-4a27-946d-0a3e96111f65" />

Status codes 404 and 200 have higher counts compared to other codes in the logs. A 404 occurs when the requested resource is not found on the server, indicating broken links or missing files. A 200 occurs when the request is successful and the server returns the requested resource, indicating normal, successful traffic.

### 3. HTTP Status Code Analysis

 ```
 index=* sourcetype=httplogs
| stats count by status
```
This SPL command helps us to monitor and analyze HTTP status codes generated by web servers.
It shows how many times each status code appeared in the logs, giving quick insight into the overall health and security posture of web applications.

<img width="926" height="409" alt="stats for status 6" src="https://github.com/user-attachments/assets/9ea32e4e-b3ca-4d49-9e45-c606967ead49" />

The results show that 404 (Not Found) and 200 (OK) occur most frequently, indicating many missing resources and normal successful requests. Other codes like 403 (Forbidden), 400 (Bad Request), and 301/302 (Redirects) appear less often, reflecting access restrictions or URL redirections. Overall, this helps understand web traffic patterns and identify potential issues like broken links or unauthorized access attempts.

### 4.Top Destination Ports Analysis
```
index=* sourcetype=httplogs
| top limit=dst_port
```
This is useful for network monitoring and threat detection. By checking which destination ports are being accessed most often, analysts can understand normal traffic patterns and quickly spot unusual activity.

<img width="932" height="410" alt="top limit (dstport) 7" src="https://github.com/user-attachments/assets/7b790414-9a15-400d-aedc-81084f73094a" />

The results show that port 80 dominates traffic, accounting for over 96% of requests, which is typical for standard HTTP traffic. Other ports like 31328, 4868, and 8080 appear much less frequently, indicating occasional alternative services or applications. This analysis helps understand network usage patterns and highlights the primary ports handling web traffic.

### 5. Detecting Anomalies in File Transfer Activity
```
index=* sourcetype=httplogs
| timechart span=1h count
```
It creates a time chart that shows the number of events or file transfers each hour.
If the chart shows a sudden increase or decrease in activity, it might mean something unusual is happening .For example, a lot of files being transferred at once or the service not working properly.

This helps us understand normal file transfer patterns and quickly notice when something looks different.

<img width="924" height="400" alt="time chart 8" src="https://github.com/user-attachments/assets/8308e8ed-b5ee-450a-9f42-601ab9989ef3" />

The results show some hours with a lot of activity, like 16:30 and 20:30, while other hours have no traffic at all. These gaps could be caused by server downtime, maintenance, or logging issues.

### 6. Analyzing High Volumes of Error Responses
```
index=* sourcetype=httplogs
| stats count by status
| where status >= 400
```
It searches our HTTP logs, counts how many times each status code appears, and then filters to show only those with status codes 400 and above.

These status codes represent client and server errors .
If you see a high number of these errors, it could mean something is wrong  such as broken links, misconfigurations, or issues with the web server. This helps us easily identify when too many errors are happening and which types are most common.

<img width="929" height="413" alt="stats count fourhundred 9" src="https://github.com/user-attachments/assets/3dcde769-f230-4dec-b979-f887078a39f7" />

I have analyzed the HTTP logs to focus on client and server error responses (status codes 400 and above). The results show that 404 (Not Found) is by far the most common error, indicating many missing resources. Other notable errors include 400 (Bad Request), 403 (Forbidden), and 401 (Unauthorized), reflecting issues with client requests or access restrictions. Server-side errors like 500 and 501 are less frequent but highlight occasional server problems that may need attention.

### 7. Identifying Failed Login Attempts
```
index=* sourcetype=httplogs action="login" status=404
| stats count by src_ip 
| sort -count
```
This SPL command helps find which IP addresses are generating failed login attempts.

<img width="934" height="415" alt="which client IPs are generating the most failed login attempts 10" src="https://github.com/user-attachments/assets/fa1c7647-c33b-4541-ad5d-d59e049ff270" />

The IP 192.168.202.110 generated the most failed login attempts (442), suggesting possible brute force activity or misconfiguration , the other IPs show significantly fewer failed attempts.

## Conclusion 

After analyzing the HTTP logs, I was able to understand how the web traffic behaves and how the server is performing. By checking status codes, destination ports, traffic patterns, errors, and login activity, I could spot unusual patterns and identify issues. This analysis helped me see where things are working well and where there might be problems, making it easier to ensure the web services run smoothly.














